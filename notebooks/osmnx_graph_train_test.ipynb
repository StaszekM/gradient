{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import sys\n",
    "sys.path.append('../.') \n",
    "from src.graph.create_osmnx_graph import OSMnxGraph\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import networkx as nx\n",
    "%reload_ext autoreload\n",
    "from src.baseline_models.GCN.supervised_node_classification import SupervisedNodeClassificationGNN\n",
    "from src.baseline_models.GCN.gcn import GCNModel\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pytorch_lightning as pl\n",
    "from src.baseline_models.GCN.GraphData import GraphData\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from shapely.geometry import Point"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "source": [
    "df_accidents = pd.read_csv(\"../data/wypadki-pl/accidents.csv\")\n",
    "df_accidents.drop(df_accidents[(df_accidents['mie_nazwa'] != 'Warszawa')].index, inplace=True)\n",
    "df_accidents.drop(columns='uczestnicy', inplace=True)\n",
    "geometry = [Point(xy) for xy in zip(df_accidents['wsp_gps_x'], df_accidents['wsp_gps_y'])]\n",
    "gdf_accidents = gpd.GeoDataFrame(df_accidents, geometry=geometry)\n",
    "gdf_accidents.drop(columns=['wsp_gps_x', 'wsp_gps_y'], inplace=True)\n",
    "G =ox.graph.graph_from_place(\"Warsaw, Poland\", network_type=\"drive\")\n",
    "gdf_nodes, gdf_edges = ox.graph_to_gdfs(G)\n",
    "gdf_nodes"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "source": [
    "gdf_edges"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informacje o przetwarzaniu cech\n",
    "\n",
    "### Krawędzie\n",
    "Wszystkie zgromadzone cechy potraktowano analogicznie jak w pracy magisterskiej z road networks za wyjątkiem atrybutów: psv, service, busway, bicycle, cycleway i surface, które nie pojawiły się w zestawieniu (po prostu nie było ich po pobraniu przez osmnx).\n",
    "\n",
    "Preprocessing obejmował:\n",
    "* lanes - dodanie domyślnej wartości 2\n",
    "* maxspeed - dodanie domyślnej wartości 50\n",
    "* width - dodanie domyślnej wartości 2.0\n",
    "* pozostałe - dodanie wartości \"unspecified\"\n",
    "\n",
    "\n",
    "### Wierzchołki\n",
    "\n",
    "Preprocessing obejmował rozbicie CountVectorizerem wartości z kolumny \"highway\", \"street_count\" pozostawiono jako wartość numeryczną bez zmian\n",
    "\n",
    "\n",
    "\n",
    "W obu przypadkach (krawędzie i wierzchołki) usunięto kolumnę \"ref\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agregacja do wierzchołków\n",
    "\n",
    "## 1. Tworzenie grafu i statystyki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "source": [
    "graph_embedder = OSMnxGraph(gdf_accidents, gdf_nodes, gdf_edges)\n",
    "\n",
    "graph_data = graph_embedder.create_graph(aggregation_type='node')\n",
    "graph_data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "source": [
    "graph_embedder.show_statistics()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "source": [
    "graph_data.num_features"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "source": [
    "len(graph_data.y.unique())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej znajduje się wywołanie metody do pozyskiwania cech wierzchołków."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "source": [
    "features = graph_embedder.get_node_attrs()\n",
    "features"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Uczenie i testowanie modelu - Supervised node classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_features = graph_data.num_features\n",
    "hidden_dim = 256\n",
    "out_dim = 128\n",
    "num_classes = len(graph_data.y.unique())\n",
    "\n",
    "gnn = GCNModel(in_dim=num_features, hidden_dim=hidden_dim, out_dim=out_dim)\n",
    "\n",
    "model = SupervisedNodeClassificationGNN(gnn=gnn, emb_dim=out_dim, num_classes=num_classes, lr=0.0001)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "source": [
    "\n",
    "nodes_labels = {'node': features.index.to_numpy(), 'label': graph_data.y.cpu().numpy()}\n",
    "df_to_split = pd.DataFrame(nodes_labels)\n",
    "\n",
    "df_train, df_test = train_test_split(df_to_split, test_size=0.2, random_state=42, stratify=df_to_split['label'])\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=42, stratify=df_test['label'])\n",
    "\n",
    "train_nodes = df_train['node']\n",
    "val_nodes = df_val['node']\n",
    "test_nodes = df_test['node']\n",
    "\n",
    "train_mask = []   \n",
    "val_mask = []\n",
    "test_mask = []\n",
    "\n",
    "for i in range(len(graph_data.y)):\n",
    "\n",
    "  if i in train_nodes:\n",
    "    train_mask.append(True)\n",
    "    val_mask.append(False)\n",
    "    test_mask.append(False)\n",
    "  elif i in val_nodes:\n",
    "    train_mask.append(False)\n",
    "    val_mask.append(True)\n",
    "    test_mask.append(False)\n",
    "  elif i in test_nodes:\n",
    "    train_mask.append(False)\n",
    "    val_mask.append(False)\n",
    "    test_mask.append(True)\n",
    "\n",
    "graph_data.train_mask = torch.tensor(train_mask).cpu()\n",
    "graph_data.val_mask = torch.tensor(val_mask).cpu()\n",
    "graph_data.test_mask = torch.tensor(test_mask).cpu()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "\n",
    "trainer = pl.Trainer(max_epochs=50)\n",
    "datamodule = GraphData([graph_data])\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "source": [
    "trainer.test(model=model, datamodule=datamodule, verbose=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "source": [
    "test_auc = trainer.test(model=model, datamodule=datamodule, verbose=False)[0][\"test/auc_weighted\"]\n",
    "\n",
    "z, y, y_pred = trainer.predict(model=model, datamodule=datamodule)[0]\n",
    "\n",
    "print(f'AUC test = {test_auc * 100.:.2f}[%]')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "source": [
    "y_pred"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "source": [
    "print(y[test_mask].numpy())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agregacja do krawędzi\n",
    "\n",
    "## 1. Tworzenie grafu i statystyki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "source": [
    "graph_embedder = OSMnxGraph(gdf_accidents, gdf_nodes, gdf_edges)\n",
    "\n",
    "graph_data = graph_embedder.create_graph(aggregation_type='edge')\n",
    "graph_data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "source": [
    "graph_embedder.show_statistics()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "source": [
    "features = graph_embedder.get_edge_attrs()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Uczenie i testowanie modelu - Supervised node classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_features = graph_data.num_features\n",
    "hidden_dim = 256\n",
    "out_dim = 128\n",
    "num_classes = len(graph_data.y.unique())\n",
    "\n",
    "gnn = GCNModel(in_dim=num_features, hidden_dim=hidden_dim, out_dim=out_dim)\n",
    "\n",
    "model = SupervisedNodeClassificationGNN(gnn=gnn, emb_dim=out_dim, num_classes=num_classes, lr=0.0001)\n",
    "\n",
    "nodes_labels = {'node': features.index.to_numpy(), 'label': graph_data.y.cpu().numpy()}\n",
    "df_to_split = pd.DataFrame(nodes_labels)\n",
    "\n",
    "df_train, df_test = train_test_split(df_to_split, test_size=0.2, random_state=42, stratify=df_to_split['label'])\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=42, stratify=df_test['label'])\n",
    "\n",
    "train_nodes = df_train['node']\n",
    "val_nodes = df_val['node']\n",
    "test_nodes = df_test['node']\n",
    "\n",
    "train_mask = []   \n",
    "val_mask = []\n",
    "test_mask = []\n",
    "\n",
    "for i in range(len(graph_data.y)):\n",
    "\n",
    "  if i in train_nodes:\n",
    "    train_mask.append(True)\n",
    "    val_mask.append(False)\n",
    "    test_mask.append(False)\n",
    "  elif i in val_nodes:\n",
    "    train_mask.append(False)\n",
    "    val_mask.append(True)\n",
    "    test_mask.append(False)\n",
    "  elif i in test_nodes:\n",
    "    train_mask.append(False)\n",
    "    val_mask.append(False)\n",
    "    test_mask.append(True)\n",
    "\n",
    "graph_data.train_mask = torch.tensor(train_mask).cpu()\n",
    "graph_data.val_mask = torch.tensor(val_mask).cpu()\n",
    "graph_data.test_mask = torch.tensor(test_mask).cpu()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=50)\n",
    "datamodule = GraphData([graph_data])\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "source": [
    "trainer.test(model=model, datamodule=datamodule, verbose=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "source": [
    "test_auc = trainer.test(model=model, datamodule=datamodule, verbose=False)[0][\"test/auc_weighted\"]\n",
    "\n",
    "z, y, y_pred = trainer.predict(model=model, datamodule=datamodule)[0]\n",
    "\n",
    "print(f'AUC test = {test_auc * 100.:.2f}[%]')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "source": [
    "y_pred"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "source": [
    "y_pred.max()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
